{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "g20_teacher_net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ali142yXsgxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch as torch\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable as var\n",
        "from gtsrb_dataset import GTSRB\n",
        "import logging as log\n",
        "import gc\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7mTQcprFJnY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c76d3d43-ab01-4bc2-bd2d-cc9aa4617964"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun 30 10:16:32 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    34W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njUvtjGO4qcm",
        "colab_type": "text"
      },
      "source": [
        "# Utility Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWnZP5Ph4svv",
        "colab_type": "text"
      },
      "source": [
        "## Garbage collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhCyJXiu1vHZ",
        "colab_type": "text"
      },
      "source": [
        "## Save Model State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvjXHikSuZrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveModel(epoch, model,optimizer,loss,path):\n",
        "  torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'loss': loss\n",
        "              }, path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l37Tk_o11yIO",
        "colab_type": "text"
      },
      "source": [
        "## Load Model State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72pnhO3N1zyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadModel(model,optimizer,path):\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "\n",
        "    print('Epoch: ',epoch,'Loss: ',loss)\n",
        "    return model,optimizer, epoch, loss;"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2oxkVh35LYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Notifying\n",
        "from twilio.rest import Client\n",
        "\n",
        "def send_text(epoch,loss,acc):\n",
        "  account_sid = 'ACddba861746e4cfc2970856833c4a0b2f'\n",
        "  auth_token = 'b1daaceeec0758a3ff72d171cf386957'\n",
        "  client = Client(account_sid, auth_token)\n",
        "  txt = \"Epoch: \"+str(epoch)+\" Loss: \"+str(loss)+\" Accuracy: \"+str(acc)\n",
        "\n",
        "  message = client.messages.create(\n",
        "                                body=txt,\n",
        "                                from_='whatsapp:+14155238886',\n",
        "                                to='whatsapp:+31633459670'\n",
        "                            )\n",
        "\n",
        "  print(message.sid)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re3ZtXBa_l8p",
        "colab_type": "text"
      },
      "source": [
        "# CUDA availability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spv5x5XavWQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg6HyJNp_tcx",
        "colab_type": "text"
      },
      "source": [
        "# Defining the Hyper-parameters for Teacher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eWzqwMiwV54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 1000\n",
        "weight_decay = 0.0001\n",
        "k = 64 ## Growth rate and batch size"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwPdDq8Zvrkx",
        "colab_type": "text"
      },
      "source": [
        "## Loading GTSRB Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bmN4bcPvuY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.3403, 0.3121, 0.3214),\n",
        "                         (0.2724, 0.2608, 0.2669))\n",
        "])\n",
        "\n",
        "train_data = GTSRB(\n",
        "    root_dir='./data/', train=True,  transform=transform)\n",
        "test_data = GTSRB(\n",
        "    root_dir='./data/', train=False,  transform=transform)\n",
        "\n",
        "train_set = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=k,shuffle=True,num_workers = 4, pin_memory=True)\n",
        "test_set = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=k,shuffle=False,num_workers = 4,pin_memory=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFBZ92U75MuD",
        "colab_type": "text"
      },
      "source": [
        "# Defining the Teacher Network\n",
        "The following sub-sections define the various parts of the Teacher Network.\n",
        "We start by defining the Cell block, followed by the Stage module and finally the complete teacher model as defined in the paper \\\\\n",
        "[Lightweight deep network for traffic sign classification, Zhang et. al (2019)](https://rdcu.be/b5aTv)\n",
        "\n",
        "Before coding the network, we show the visual description of how the network looks with images taken from the above paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsCyzdxZkGUS",
        "colab_type": "text"
      },
      "source": [
        "## Cell Block\n",
        "\n",
        "*The 1 × 1 kernels and the 3 × 3 kernels execute convolution\n",
        "operations in parallel and splice all output results*\n",
        "\n",
        "![Cell Block](https://i.imgur.com/RWMjelN.png)\n",
        "\n",
        "Please note, the numbers 64 on each on the convolution operations are, as per our interpretation, used to denote that each of the convolution operations see exactly half of the input(as the batch size mentioned in the paper is 128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8zB6K6AwptD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Cell(nn.Module):\n",
        "  def __init__(self,cell_in_channels,cell_out_channels):\n",
        "    super(Cell, self).__init__()\n",
        "\n",
        "    self.activation_function = nn.ReLU()\n",
        "    self.batch_norm = nn.BatchNorm2d(cell_out_channels)\n",
        "\n",
        "    ## Reflect padding is used for the 3 x 3 convolution as it creates a \n",
        "    ## feature map of size 30 X 30, and needs to be padded to 32 x 32\n",
        "    ## in order to concatenate with the 1 x 1 conv tensor\n",
        "\n",
        "    self.cnn3 = nn.Conv2d(in_channels=int(cell_in_channels/2),\n",
        "                          out_channels=int(cell_out_channels/2),\n",
        "                          kernel_size=3,padding=1,padding_mode='reflect', \n",
        "                          stride=1)\n",
        "    \n",
        "    self.cnn1 = nn.Conv2d(in_channels=int(cell_in_channels/2), \n",
        "                          out_channels=int(cell_out_channels/2),\n",
        "                          kernel_size=1, stride=1)\n",
        "    \n",
        "    \n",
        "    '''\n",
        "    I had initially thought about directly using grouped convolution feature, but could not find an implemented way of using different sized kernels for the parallel groups\n",
        "    '''\n",
        "    # self.grouped_conv = nn.Conv2d(in_channels=int(cell_in_channels/2), \n",
        "    #                               out_channels=int(cell_out_channels/2),\n",
        "    #                               kernel_size=1, stride=1,groups=2)\n",
        "\n",
        "\n",
        "    ## Used to split the input tensor in half in order to run parallel convolution\n",
        "    self.split_size = int(cell_in_channels/2)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    (path1,path2) = torch.split(x,split_size_or_sections=[self.split_size,self.split_size],dim=1)\n",
        "    path1 = self.cnn1(path1)\n",
        "\n",
        "    path2 = self.cnn3(path2)\n",
        "\n",
        "    x = torch.cat([path1,path2],1)\n",
        "    x = self.batch_norm(x)\n",
        "    x = self.activation_function(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1J1kCbckXmf",
        "colab_type": "text"
      },
      "source": [
        "## Stage Module\n",
        "*Six cells are\n",
        "used to establish the direct connection between different\n",
        "layers, making full use of the feature maps of each layer*\n",
        "\n",
        "![stage](https://i.imgur.com/szNZQ9Cm.jpg)\n",
        "\n",
        "The outputs from each of the cells, as well as the 1 x 1 convolution are accumulated into the input for the next cell\n",
        "\n",
        "The two 1 x 1 convolutions are used to reduce the number of feature maps when connecting between the two stages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6zKrgG20Xbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Stage(nn.Module):\n",
        "  def __init__(self,cell_connections_in, cell_connections_out,stage_in,stage_out):\n",
        "    super(Stage,self).__init__()\n",
        "\n",
        "    self.activation_function = nn.ReLU()\n",
        "    self.batch_norm = nn.BatchNorm2d(k)\n",
        "\n",
        "    self.cnn1 = nn.Conv2d(in_channels=stage_in,\n",
        "                          out_channels=k,kernel_size=1,\n",
        "                          stride=1)\n",
        "    \n",
        "    self.cnn2 = nn.Conv2d(in_channels=7*k,\n",
        "                          out_channels=stage_out,kernel_size=1,\n",
        "                          stride=1)\n",
        "    \n",
        "    ## Densely connected six cell blocks\n",
        "    self.cells = nn.ModuleList([\n",
        "                                Cell(cell_connections_in[i],\n",
        "                                     cell_connections_out[i]) for i in range(6)\n",
        "                                     ])      \n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    #print(x.size())\n",
        "    cell_results = []\n",
        "    x = self.cnn1(x)\n",
        "    x = self.batch_norm(x)\n",
        "    x = self.activation_function(x)\n",
        "\n",
        "    cell_results.append(x)\n",
        "    for i in range(6):\n",
        "      #print('Cell ',i)\n",
        "      x = torch.cat(cell_results,1)\n",
        "      x = self.cells[i](x)\n",
        "      cell_results.append(x);\n",
        "      \n",
        "    x = torch.cat(cell_results,1)\n",
        "\n",
        "    x = self.cnn2(x)\n",
        "    x = self.batch_norm(x)\n",
        "    x = self.activation_function(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VduCbXykyqJ",
        "colab_type": "text"
      },
      "source": [
        "## Teacher Network\n",
        "![teacher](https://i.imgur.com/bTH8KSCm.jpg)\n",
        "\n",
        "Finally, we define the teacher network which consists of 4 stage modules connected in a dense fashion, with each stage producing a 'k' feature maps where 'k' is the growth rate of the network.\n",
        "\n",
        "Stage 0 takes the input tensor which has 3 x H X W tensor and outputs a k x H x W tensor. The remaining Stages take 'k' feature maps as input and output 'k' feature maps\n",
        "\n",
        "Finally, the Stage 3 output is pooled using a 3 x 3 max pooling with stride of 2\n",
        "and finally a fully connected linear layer which produces the probability vector for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4H42GR4Cl31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TeacherNetwork(nn.Module):\n",
        "  def __init__(self,cell_onnections_in,cell_connections_out,stage_connections_in,stage_connections_out):\n",
        "    super(TeacherNetwork, self).__init__()\n",
        "\n",
        "    self.stages = nn.ModuleList([Stage(cell_onnections_in,cell_connections_out,stage_connections_in[i],stage_connections_out[i]) for i in range(4)])\n",
        "    self.max_pool = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    self.activation_function = nn.ReLU()\n",
        "    self.linear = nn.Linear(in_features=65536,out_features=43)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    stage_results = []\n",
        "    for i in range(4):\n",
        "      #print('Stage ',i)\n",
        "      if i != 0:\n",
        "        x = torch.cat(stage_results,1)\n",
        "        x = self.stages[i](x)\n",
        "        stage_results.append(x);\n",
        "\n",
        "      else:\n",
        "        x = self.stages[0](x)\n",
        "        stage_results.append(x)\n",
        "    \n",
        "    x = torch.cat(stage_results,1)\n",
        "    x = self.max_pool(x)\n",
        "    # print(x.size())\n",
        "    x = x.view(x.size(0),-1)\n",
        "    # print(x.size())\n",
        "    x = self.linear(x)\n",
        "    #print(\"Sending prediction now!\")\n",
        "    return x;"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL19QLjS92iX",
        "colab_type": "text"
      },
      "source": [
        "# Validation Function\n",
        "\n",
        "Validates the model against the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbDPqodr4F4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model,data):\n",
        "  # To get validation accuracy = (correct/total)*100.\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for i,(images,labels) in enumerate(data):\n",
        "      images = var(images.cuda())\n",
        "      x = model(images)\n",
        "      value,pred = torch.max(x,1)\n",
        "      pred = pred.data.cpu()\n",
        "      total += x.size(0)\n",
        "      correct += torch.sum(pred == labels)\n",
        "    return correct*100./total"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIkgxABI4Lx6",
        "colab_type": "text"
      },
      "source": [
        "# Defining the Teacher Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CquiAVXIJjXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "The cells use feature maps from every preceding output in the subsequent cells,\n",
        "increasing the number of feature maps for every next cell by k * 2^(i-1) where \n",
        "i is the cell number. Therefore, the first cell inputs 'k' feature maps and \n",
        "outputs k feature maps, and the last cell(6th) inputs 2^5 * k feature maps and \n",
        "outputs the same number\n",
        "'''\n",
        "cell_connections_in = [k,2*k,3*k,4*k,5*k,6*k]\n",
        "cell_connections_out = [k] * 6\n",
        "\n",
        "'''\n",
        "The stages also use feature maps from every preceding output in the subsequent \n",
        "cells, increasing the number of feature maps for every next stage linearly. \n",
        "This is due to the fact that the 1 x 1 convolution at the end of every stage \n",
        "reduces the output feature maps to size 'k'\n",
        "'''\n",
        "\n",
        "stage_connections_in = [3,k,2*k,3*k]\n",
        "stage_connections_out = [k] * 4\n",
        "\n",
        "teacher = TeacherNetwork(cell_connections_in,cell_connections_out,stage_connections_in,stage_connections_out).to(device)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvMq0nE84Qte",
        "colab_type": "text"
      },
      "source": [
        "## Defining the Loss Function for Teacher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htNzesAM4TU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cec = nn.CrossEntropyLoss().cuda()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBLSjLL24CEv",
        "colab_type": "text"
      },
      "source": [
        "## Checking the Teacher Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaQT-6r4rjW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7yOv1dp4Xbg",
        "colab_type": "text"
      },
      "source": [
        "## Parameter Count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix8_eq7tJm_2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88600fdc-f084-4464-e1df-2e60445dc4a3"
      },
      "source": [
        "s  = sum(np.prod(list(p.size())) for p in teacher.parameters())\n",
        "print('Number of parameters: ',s)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters:  3823339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-NknvXkAmRn",
        "colab_type": "text"
      },
      "source": [
        "## Defining the Optimizer\n",
        "We use an ADAM optimizer with a defined initial learning rate and a weight decay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na5GdypGAluR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(teacher.parameters(),lr=learning_rate,weight_decay=weight_decay)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW475xsu7TV4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f311e77d-8c1d-4044-a5d4-0270c8eb7b91"
      },
      "source": [
        "teacher"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TeacherNetwork(\n",
              "  (stages): ModuleList(\n",
              "    (0): Stage(\n",
              "      (activation_function): ReLU()\n",
              "      (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (cnn1): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (cnn2): Conv2d(448, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (cells): ModuleList(\n",
              "        (0): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (4): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (5): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): Stage(\n",
              "      (activation_function): ReLU()\n",
              "      (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (cnn1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (cnn2): Conv2d(448, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (cells): ModuleList(\n",
              "        (0): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (4): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (5): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): Stage(\n",
              "      (activation_function): ReLU()\n",
              "      (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (cnn1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (cnn2): Conv2d(448, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (cells): ModuleList(\n",
              "        (0): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (4): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (5): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): Stage(\n",
              "      (activation_function): ReLU()\n",
              "      (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (cnn1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (cnn2): Conv2d(448, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (cells): ModuleList(\n",
              "        (0): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (4): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (5): Cell(\n",
              "          (activation_function): ReLU()\n",
              "          (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (cnn3): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
              "          (cnn1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (activation_function): ReLU()\n",
              "  (linear): Linear(in_features=65536, out_features=43, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alSGOA217WeO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d6448682-fd4e-4422-b405-42881dcede1a"
      },
      "source": [
        "optimizer"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    eps: 1e-08\n",
              "    lr: 0.001\n",
              "    weight_decay: 0.0001\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj6CTooWAKVc",
        "colab_type": "text"
      },
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CC-Z85WDtab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for e in range(epochs)[(epoch+1):]:\n",
        "  epoch_loss = 0.0\n",
        "  running_loss = 0.0\n",
        "  for i,(images,labels) in enumerate(train_set):\n",
        "    teacher.train()\n",
        "    images = var(images.cuda())\n",
        "    labels = var(labels.cuda())\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    prediction = teacher(images)\n",
        "    loss = cec(prediction,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += prediction.shape[0] * loss.item()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "    \n",
        "    if (i+1) % 100 == 0:\n",
        "      print('Epoch :',e+1,'Batch :',(i+1),'Loss :',running_loss/100)\n",
        "      running_loss = 0.0\n",
        "  \n",
        "  accuracy = float(validate(teacher,test_set))\n",
        "  print('Epoch: ',e+1,'Loss: ',(epoch_loss/len(train_set)),'Accuracy: ',accuracy,'%')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_LUOrjaA8AB",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsWqIix32bLG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a607f59-d488-40f1-e22f-8b5da48bb204"
      },
      "source": [
        "accuracy = float(validate(teacher,test_set))\n",
        "print('Accuracy = ',accuracy)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  89.88915252685547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEfsJ7OChvS",
        "colab_type": "text"
      },
      "source": [
        "# Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seU8hwRxCRRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(teacher,\"./saved_models/trained_teacher_model.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}